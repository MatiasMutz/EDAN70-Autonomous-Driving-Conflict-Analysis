{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5181d591cea5ff1",
   "metadata": {},
   "source": [
    "The first thing we do is to import the necessary libraries. As seen in the dataset github repository (https://github.com/RomainLITUD/conflict_resolution_dataset) we need to import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41051d7e72b2ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:26:17.895145Z",
     "start_time": "2025-04-16T11:26:16.443133Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import os\n",
    "from dataset.visual_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3e385ab90a894",
   "metadata": {},
   "source": [
    "Read and visualize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56a797544bb651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:26:20.774358Z",
     "start_time": "2025-04-16T11:26:20.549797Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_av = 'av'\n",
    "folder_hv = 'hv'\n",
    "\n",
    "root_av = './dataset/data_3m/'+folder_av+'/'\n",
    "root_hv = './dataset/data_3m/'+folder_hv+'/'\n",
    "\n",
    "log_ids_av = [name for name in os.listdir(root_av) if name.endswith('.zarr')]\n",
    "log_ids_hv = [name for name in os.listdir(root_hv) if name.endswith('.zarr')]\n",
    "\n",
    "print('Number of scenarios for Autonomous Vehicles: ', len(log_ids_av))\n",
    "print('Number of scenarios for Human-driven Vehicles: ', len(log_ids_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b019d2fb21715d",
   "metadata": {},
   "source": [
    "Read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3582b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:26:25.470632Z",
     "start_time": "2025-04-16T11:26:25.460987Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "slices: len = nb_objects + 1, slices[n] and slices[n+1] gives the start/end indices of the n-th object\n",
    "maps: lanes as NumPy array\n",
    "type: len = nb_objects, contains 7 numbers with the following meanings:\n",
    "        -1: Static background\n",
    "        0: human-driven vehicles\n",
    "        1: pedestrians\n",
    "        2: motorcyclists\n",
    "        3: cyclists\n",
    "        4: buses\n",
    "        10: autonomous vehicles\n",
    "timestep: timestamps in second, timestep[slices[n]: slices[n+1]] give the timestamps for the n-th object\n",
    "motion: motion state, with 7 dimensions\n",
    "    motion[slices[n]: slices[n+1]] gives the motion of the n-th object, the 7 features are the following variables in order:\n",
    "        [x, y, vx, vy, ax, ay, yaw]\n",
    "        yaw is to the x-axis, between [-pi, pi]\n",
    "'''\n",
    "# Use the first scenario as an example\n",
    "slices, timestep, motion, type, maps = read_scenario(log_ids_av[0], root_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f2f03",
   "metadata": {},
   "source": [
    "Visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58908621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:26:28.554660Z",
     "start_time": "2025-04-16T11:26:28.431994Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = visualize(log_ids_av[0], root_av, other_road_users=True, direction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc12ddf",
   "metadata": {},
   "source": [
    "Filter the data:\n",
    "\n",
    "The metafile contains the following information:\n",
    "log_id: string, index of the scenario\n",
    "[xi_start, yi_start]: float, direction vector of the first* agent recorded in the scenario at the start** time\n",
    "[xj_start, yj_start]: float, direction vector of the second agent recorded in the scenario at the start time\n",
    "typei: str, agent type of the first agent recorded in the scenario, being one of {'AV','HV','Pedestrian','Motorcyclist','Cyclist','Bus'}\n",
    "[xi_end, yi_end]: float, direction vector of the first* agent recorded in the scenario at the end*** time\n",
    "[xj_end, yj_end]: float, direction vector of the second agent recorded in the scenario at the end time\n",
    "typej: str, agent type of the second agent recorded in the scenario, being one of {'AV','HV','Pedestrian','Motorcyclist','Cyclist','Bus'}\n",
    "direction: str, whether the second-passing vehicle moved from the left ('L-R') or the right ('R-L') of the first-passing agent\n",
    "PET: float, post-encroachment-time\n",
    "ifirst: bool, whether the first-passing agent is the first agent recorded in the scenario\n",
    "angle_start: float, angle between the direction vectors of the two agents at the start time\n",
    "angle_end: float, angle between the direction vectors of the two agents at the end time\n",
    "start: str, whether the two agents ran parallel (P), crossed (C), or ran opposite (O) to each other before reaching the conflict point\n",
    "end: str, whether the two agents ran parallel (P), crossed (C), or ran opposite (O) to each other after reaching the conflict point\n",
    "\n",
    "Notes:\n",
    "    * Note that the first agent does not necessarily pass the conflict point first.\n",
    "    ** We consider the start time as 5 seconds before the first-passing agent passed the conflict point, or the start of the record if the time before passing the conflict point is less than 5 seconds.\n",
    "    *** Similarly, the end time is 5 seconds after the second-passing vehicle passed the conflict point, or the end of the record if the time after passing the conflict point is less than 5 seconds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147ab84",
   "metadata": {},
   "source": [
    "We'll load the metafile and filter for intersection scenarios based on the 'angle_start' and 'angle_end' fields, which indicate crossing trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c20a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:27:01.470030Z",
     "start_time": "2025-04-16T11:27:01.421700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load metafile for autonomous vehicles\n",
    "metafile_av = pd.read_csv('./dataset/metafile_av.csv')\n",
    "\n",
    "# Filter for intersection scenarios (crossing trajectories)\n",
    "intersection_cases = metafile_av[\n",
    "    ((metafile_av['start'] == 'cross') | (metafile_av['end'] == 'cross')) &\n",
    "    (metafile_av['typej'] != 'Pedestrian')\n",
    "]\n",
    "\n",
    "print(f\"Total number of intersection scenarios: {len(intersection_cases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06353478",
   "metadata": {},
   "source": [
    "We define three functions, one to get the scenario filename, one to analyze the scenario and one to visualize the scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bac9cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:27:03.369168Z",
     "start_time": "2025-04-16T11:27:03.360174Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scenario_filename(scenario_id, root_path):\n",
    "    \"\"\"\n",
    "    Maps a scenario ID to its corresponding zarr file in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        scenario_id (str): The ID of the scenario to find\n",
    "        root_path (str): Root directory containing the scenario files\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Filename if found, None if no matching file exists\n",
    "    \"\"\"\n",
    "    # List all files in the directory\n",
    "    all_files = os.listdir(root_path)\n",
    "    \n",
    "    # Try different possible filename formats\n",
    "    possible_formats = [\n",
    "        f\"{int(scenario_id):02d}.zarr\",  # 01.zarr\n",
    "        f\"{scenario_id}.zarr\",           # 1.zarr\n",
    "        f\"scenario_{scenario_id}.zarr\",  # scenario_1.zarr\n",
    "        f\"scenario_{int(scenario_id):02d}.zarr\"  # scenario_01.zarr\n",
    "    ]\n",
    "    \n",
    "    # Try each format\n",
    "    for format in possible_formats:\n",
    "        if format in all_files:\n",
    "            return format\n",
    "    \n",
    "    # If no exact match, try to find any file containing the scenario number\n",
    "    matching_files = [f for f in all_files if str(int(scenario_id)) in f and f.endswith('.zarr')]\n",
    "    \n",
    "    if matching_files:\n",
    "        return matching_files[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def analyze_intersection_scenario(scenario_id, root_path):\n",
    "    \"\"\"\n",
    "    Analyzes a single intersection scenario and extracts relevant features for conflict detection.\n",
    "    \n",
    "    Args:\n",
    "        scenario_id (str): The ID of the scenario to analyze\n",
    "        root_path (str): Root directory containing the scenario files\n",
    "        \n",
    "    Returns:\n",
    "        dict or None: Dictionary containing scenario features if successful:\n",
    "            - scenario_id: ID of the analyzed scenario\n",
    "            - trajectory_length: Number of timesteps in the scenario\n",
    "            - vehicle_count: Number of vehicles in the scenario\n",
    "            - motion_data: Vehicle motion states (position, velocity, acceleration, yaw)\n",
    "            - timestep: Timestamps for each motion state\n",
    "            - slices: Indices marking different vehicles' data\n",
    "            - type_data: Vehicle type information\n",
    "        Returns None if analysis fails\n",
    "    \"\"\"\n",
    "    filename = get_scenario_filename(scenario_id, root_path)\n",
    "    if filename is None:\n",
    "        print(f\"Error: No matching file found for scenario {scenario_id}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        slices, timestep, motion, type_data, maps = read_scenario(filename, root_path)\n",
    "        \n",
    "        features = {\n",
    "            'scenario_id': scenario_id,\n",
    "            'trajectory_length': len(timestep),\n",
    "            'vehicle_count': len(type_data),\n",
    "            'motion_data': motion,\n",
    "            'timestep': timestep,\n",
    "            'slices': slices,\n",
    "            'type_data': type_data\n",
    "        }\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing scenario {scenario_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def visualize_scenario(scenario_id, root_path):\n",
    "    \"\"\"Visualizes a single scenario with trajectory information.\"\"\"\n",
    "    try:\n",
    "        filename = get_scenario_filename(scenario_id, root_path)\n",
    "        if filename:\n",
    "            fig, ax = visualize(filename, root_path, \n",
    "                              other_road_users=True, \n",
    "                              direction=True)\n",
    "            plt.title(f'Scenario {scenario_id}')\n",
    "            return fig, ax\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing scenario {scenario_id}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "    \"\"\"Visualizes a single scenario with trajectory information.\"\"\"\n",
    "    try:\n",
    "        filename = get_scenario_filename(scenario_id, root_path)\n",
    "        if filename:\n",
    "            fig, ax = visualize(filename, root_path, \n",
    "                              other_road_users=True, \n",
    "                              direction=True)\n",
    "            plt.title(f'Scenario {scenario_id}')\n",
    "            return fig, ax\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing scenario {scenario_id}: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebeed55",
   "metadata": {},
   "source": [
    "Now, we can analyze a few sample scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fd290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:27:10.662693Z",
     "start_time": "2025-04-16T11:27:09.959458Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "sample_scenarios = intersection_cases['log_id'].iloc[:sample_size]\n",
    "\n",
    "print(\"\\nAnalyzing sample scenarios:\")\n",
    "for scenario_id in sample_scenarios:\n",
    "    print(f\"\\nProcessing scenario {scenario_id}\")\n",
    "    features = analyze_intersection_scenario(scenario_id, root_av)\n",
    "    \n",
    "    if features:\n",
    "        print(f\"Successfully analyzed scenario:\")\n",
    "        print(f\"- Trajectory length: {features['trajectory_length']}\")\n",
    "        print(f\"- Number of vehicles: {features['vehicle_count']}\")\n",
    "    else:\n",
    "        print(\"Analysis failed\")\n",
    "\n",
    "# Visualize sample scenarios\n",
    "fig, axs = plt.subplots(1, min(5, len(sample_scenarios)), figsize=(20, 4))\n",
    "if not isinstance(axs, np.ndarray):\n",
    "    axs = [axs]\n",
    "\n",
    "for i, scenario_id in enumerate(sample_scenarios[:5]):\n",
    "    _, _ = visualize_scenario(scenario_id, root_av)\n",
    "    if i < len(axs):\n",
    "        axs[i].set_title(f'Scenario {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210a84b",
   "metadata": {},
   "source": [
    "Now we can do the conflict analysis for the intersection scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca5d2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:27:18.139703Z",
     "start_time": "2025-04-16T11:27:18.117854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants for conflict analysis\n",
    "CONFLICT_THRESHOLDS = {\n",
    "    'TTC_CRITICAL': 2.0,     # Critical Time-to-Collision (seconds)\n",
    "    'PET_CRITICAL': 1.0,     # Critical Post-Encroachment Time (seconds)\n",
    "    'ANGLE_THRESHOLD': {\n",
    "        'CROSSING': 45,      # Minimum angle for crossing conflict (degrees)\n",
    "        'HEAD_ON': 150       # Minimum angle for head-on conflict (degrees)\n",
    "    },\n",
    "    'DISTANCE_CRITICAL': 5.0 # Critical distance (meters)\n",
    "}\n",
    "\n",
    "class ConflictType:\n",
    "    \"\"\"Possible conflict types in autonomous driving scenarios\"\"\"\n",
    "    CROSSING = \"crossing\"           # Trajectories intersect at an angle\n",
    "    REAR_END = \"rear_end\"          # Following vehicle conflicts with leading vehicle\n",
    "    HEAD_ON = \"head_on\"            # Vehicles approaching from opposite directions\n",
    "    MERGING = \"merging\"            # Vehicle merging into traffic\n",
    "    NO_CONFLICT = \"no_conflict\"    # No conflict detected\n",
    "\n",
    "def calculate_time_to_collision(ego_motion, other_motion):\n",
    "    \"\"\"\n",
    "    Calculates Time-to-Collision (TTC) between two vehicles\n",
    "    \n",
    "    Args:\n",
    "        ego_motion: Motion data for ego vehicle [x, y, vx, vy, ...]\n",
    "        other_motion: Motion data for other vehicle [x, y, vx, vy, ...]\n",
    "    \n",
    "    Returns:\n",
    "        float: Minimum TTC value or infinity if no collision course\n",
    "    \"\"\"\n",
    "    # Interpolate trajectories to common length\n",
    "    target_length = 100\n",
    "    \n",
    "    # Create normalized time arrays for interpolation\n",
    "    t_ego = np.linspace(0, 1, len(ego_motion))\n",
    "    t_other = np.linspace(0, 1, len(other_motion))\n",
    "    t_common = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    # Initialize interpolated arrays\n",
    "    ego_interp = np.zeros((target_length, ego_motion.shape[1]))\n",
    "    other_interp = np.zeros((target_length, other_motion.shape[1]))\n",
    "    \n",
    "    # Interpolate each component\n",
    "    for i in range(ego_motion.shape[1]):\n",
    "        ego_interp[:, i] = np.interp(t_common, t_ego, ego_motion[:, i])\n",
    "        other_interp[:, i] = np.interp(t_common, t_other, other_motion[:, i])\n",
    "    \n",
    "    # Extract positions and velocities from interpolated data\n",
    "    ego_pos = ego_interp[:, :2]    # [x, y]\n",
    "    ego_vel = ego_interp[:, 2:4]   # [vx, vy]\n",
    "    other_pos = other_interp[:, :2]\n",
    "    other_vel = other_interp[:, 2:4]\n",
    "    \n",
    "    # Calculate relative velocity and distance\n",
    "    rel_pos = ego_pos - other_pos\n",
    "    rel_vel = ego_vel - other_vel\n",
    "    \n",
    "    # Calculate TTC\n",
    "    distance = np.linalg.norm(rel_pos, axis=1)\n",
    "    rel_speed = np.linalg.norm(rel_vel, axis=1)\n",
    "    \n",
    "    # Avoid division by zero and negative relative speeds\n",
    "    valid_idx = (rel_speed > 0.1)\n",
    "    if not np.any(valid_idx):\n",
    "        return float('inf')\n",
    "    \n",
    "    ttc = distance[valid_idx] / rel_speed[valid_idx]\n",
    "    return np.min(ttc) if len(ttc) > 0 else float('inf')\n",
    "\n",
    "def calculate_post_encroachment_time(ego_motion, other_motion, conflict_point=None):\n",
    "    \"\"\"\n",
    "    Calculates Post-Encroachment Time (PET) at the conflict point\n",
    "    \n",
    "    Args:\n",
    "        ego_motion: Motion data for ego vehicle\n",
    "        other_motion: Motion data for other vehicle\n",
    "        conflict_point: Optional pre-defined conflict point\n",
    "    \n",
    "    Returns:\n",
    "        float: PET value in seconds\n",
    "    \"\"\"\n",
    "    # Interpolate trajectories to common length\n",
    "    target_length = 100\n",
    "    \n",
    "    # Create normalized time arrays for interpolation\n",
    "    t_ego = np.linspace(0, 1, len(ego_motion))\n",
    "    t_other = np.linspace(0, 1, len(other_motion))\n",
    "    t_common = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    # Initialize interpolated arrays\n",
    "    ego_interp = np.zeros((target_length, ego_motion.shape[1]))\n",
    "    other_interp = np.zeros((target_length, other_motion.shape[1]))\n",
    "    \n",
    "    # Interpolate each component\n",
    "    for i in range(ego_motion.shape[1]):\n",
    "        ego_interp[:, i] = np.interp(t_common, t_ego, ego_motion[:, i])\n",
    "        other_interp[:, i] = np.interp(t_common, t_other, other_motion[:, i])\n",
    "    \n",
    "    if conflict_point is None:\n",
    "        # Estimate conflict point as the closest point between trajectories\n",
    "        ego_pos = ego_interp[:, :2]\n",
    "        other_pos = other_interp[:, :2]\n",
    "        distances = np.linalg.norm(ego_pos[:, np.newaxis] - other_pos, axis=2)\n",
    "        min_idx = np.unravel_index(np.argmin(distances), distances.shape)\n",
    "        conflict_point = (ego_pos[min_idx[0]] + other_pos[min_idx[1]]) / 2\n",
    "    \n",
    "    # Calculate arrival times at conflict point using interpolated data\n",
    "    ego_times = calculate_arrival_time(ego_interp, conflict_point)\n",
    "    other_times = calculate_arrival_time(other_interp, conflict_point)\n",
    "    \n",
    "    # PET is the absolute difference between arrival times\n",
    "    return abs(ego_times - other_times)\n",
    "\n",
    "def calculate_arrival_time(motion, point):\n",
    "    \"\"\"\n",
    "    Calculates time of arrival to a specific point\n",
    "    \n",
    "    Args:\n",
    "        motion: Vehicle motion data\n",
    "        point: Target point coordinates\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated arrival time in seconds\n",
    "    \"\"\"\n",
    "    positions = motion[:, :2]\n",
    "    velocities = motion[:, 2:4]\n",
    "    \n",
    "    # Find closest point to conflict point\n",
    "    distances = np.linalg.norm(positions - point, axis=1)\n",
    "    closest_idx = np.argmin(distances)\n",
    "    \n",
    "    # Calculate time based on distance and speed\n",
    "    speed = np.linalg.norm(velocities[closest_idx])\n",
    "    if speed < 0.1:  # Almost stopped\n",
    "        return float('inf')\n",
    "    \n",
    "    return distances[closest_idx] / speed\n",
    "\n",
    "def classify_conflict_type(ego_motion, other_motion):\n",
    "    \"\"\"\n",
    "    Classifies the type of conflict based on vehicle trajectories\n",
    "    \n",
    "    Args:\n",
    "        ego_motion: Motion data for ego vehicle\n",
    "        other_motion: Motion data for other vehicle\n",
    "    \n",
    "    Returns:\n",
    "        str: Type of conflict (CROSSING, REAR_END, HEAD_ON, MERGING)\n",
    "    \"\"\"\n",
    "    # Calculate angle between trajectories\n",
    "    ego_direction = ego_motion[-1, 2:4] - ego_motion[0, 2:4]\n",
    "    other_direction = other_motion[-1, 2:4] - other_motion[0, 2:4]\n",
    "    \n",
    "    angle = np.arccos(np.dot(ego_direction, other_direction) / \n",
    "                     (np.linalg.norm(ego_direction) * np.linalg.norm(other_direction)))\n",
    "    angle_deg = np.degrees(angle)\n",
    "    \n",
    "    # Classify based on angle\n",
    "    if angle_deg > CONFLICT_THRESHOLDS['ANGLE_THRESHOLD']['HEAD_ON']:\n",
    "        return ConflictType.HEAD_ON\n",
    "    elif angle_deg > CONFLICT_THRESHOLDS['ANGLE_THRESHOLD']['CROSSING']:\n",
    "        return ConflictType.CROSSING\n",
    "    else:\n",
    "        # Determine if rear-end or merging\n",
    "        relative_position = other_motion[0, :2] - ego_motion[0, :2]\n",
    "        heading_difference = abs(ego_motion[0, 6] - other_motion[0, 6])\n",
    "        \n",
    "        if heading_difference < np.pi/4:  # Similar directions\n",
    "            return ConflictType.REAR_END\n",
    "        else:\n",
    "            return ConflictType.MERGING\n",
    "\n",
    "def assess_risk_level(ttc, pet, distance):\n",
    "    \"\"\"\n",
    "    Evaluates risk level based on multiple metrics\n",
    "    \n",
    "    Args:\n",
    "        ttc: Time-to-Collision value\n",
    "        pet: Post-Encroachment Time value\n",
    "        distance: Minimum distance between vehicles\n",
    "    \n",
    "    Returns:\n",
    "        str: Risk level (HIGH, MEDIUM, LOW)\n",
    "    \"\"\"\n",
    "    if ttc < CONFLICT_THRESHOLDS['TTC_CRITICAL'] or \\\n",
    "       pet < CONFLICT_THRESHOLDS['PET_CRITICAL'] or \\\n",
    "       distance < CONFLICT_THRESHOLDS['DISTANCE_CRITICAL']:\n",
    "        return \"HIGH\"\n",
    "    elif ttc < CONFLICT_THRESHOLDS['TTC_CRITICAL'] * 2 or \\\n",
    "         pet < CONFLICT_THRESHOLDS['PET_CRITICAL'] * 2 or \\\n",
    "         distance < CONFLICT_THRESHOLDS['DISTANCE_CRITICAL'] * 2:\n",
    "        return \"MEDIUM\"\n",
    "    else:\n",
    "        return \"LOW\"\n",
    "\n",
    "def analyze_scenario_conflicts(scenario_data):\n",
    "    \"\"\"\n",
    "    Complete conflict analysis for a scenario\n",
    "    \n",
    "    Args:\n",
    "        scenario_data: Dictionary containing scenario information\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results including conflict type, metrics, and risk level\n",
    "    \"\"\"\n",
    "    # Extract motion data for ego and other vehicles\n",
    "    ego_motion = scenario_data['motion_data'][scenario_data['slices'][0]:scenario_data['slices'][1]]\n",
    "    other_motion = scenario_data['motion_data'][scenario_data['slices'][1]:scenario_data['slices'][2]]\n",
    "    \n",
    "    # Interpolate trajectories to common length for minimum distance calculation\n",
    "    target_length = 100\n",
    "    t_ego = np.linspace(0, 1, len(ego_motion))\n",
    "    t_other = np.linspace(0, 1, len(other_motion))\n",
    "    t_common = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    ego_interp = np.zeros((target_length, ego_motion.shape[1]))\n",
    "    other_interp = np.zeros((target_length, other_motion.shape[1]))\n",
    "    \n",
    "    for i in range(ego_motion.shape[1]):\n",
    "        ego_interp[:, i] = np.interp(t_common, t_ego, ego_motion[:, i])\n",
    "        other_interp[:, i] = np.interp(t_common, t_other, other_motion[:, i])\n",
    "    \n",
    "    # Calculate main metrics using interpolated data\n",
    "    ttc = calculate_time_to_collision(ego_motion, other_motion)\n",
    "    pet = calculate_post_encroachment_time(ego_motion, other_motion)\n",
    "    min_distance = np.min(np.linalg.norm(ego_interp[:, :2] - other_interp[:, :2], axis=1))\n",
    "    \n",
    "    # Classify conflict type (using interpolated data)\n",
    "    conflict_type = classify_conflict_type(ego_interp, other_interp)\n",
    "    \n",
    "    # Evaluate risk level\n",
    "    risk_level = assess_risk_level(ttc, pet, min_distance)\n",
    "    \n",
    "    return {\n",
    "        'scenario_id': scenario_data['scenario_id'],\n",
    "        'conflict_type': conflict_type,\n",
    "        'metrics': {\n",
    "            'TTC': ttc,\n",
    "            'PET': pet,\n",
    "            'min_distance': min_distance,\n",
    "            'risk_level': risk_level\n",
    "        },\n",
    "        'timestamp': scenario_data['timestep']\n",
    "    }\n",
    "\n",
    "def analyze_all_scenarios(intersection_cases, root_path):\n",
    "    \"\"\"\n",
    "    Analyzes all scenarios and generates a report\n",
    "    \n",
    "    Args:\n",
    "        intersection_cases: DataFrame containing scenario metadata\n",
    "        root_path: Root directory containing scenario files\n",
    "    \n",
    "    Returns:\n",
    "        list: Analysis results for all scenarios\n",
    "    \"\"\"\n",
    "    conflict_analyses = []\n",
    "    \n",
    "    for _, case in intersection_cases.iterrows():\n",
    "        scenario_id = case['log_id']\n",
    "        features = analyze_intersection_scenario(scenario_id, root_path)\n",
    "        \n",
    "        if features:\n",
    "            conflict_analysis = analyze_scenario_conflicts(features)\n",
    "            conflict_analyses.append(conflict_analysis)\n",
    "            \n",
    "            print(f\"\\nAnalysis for Scenario {scenario_id}:\")\n",
    "            print(f\"Conflict Type: {conflict_analysis['conflict_type']}\")\n",
    "            print(f\"Risk Level: {conflict_analysis['metrics']['risk_level']}\")\n",
    "            print(f\"TTC: {conflict_analysis['metrics']['TTC']:.2f} seconds\")\n",
    "            print(f\"PET: {conflict_analysis['metrics']['PET']:.2f} seconds\")\n",
    "            print(f\"Minimum Distance: {conflict_analysis['metrics']['min_distance']:.2f} meters\")\n",
    "    \n",
    "    return conflict_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f437e",
   "metadata": {},
   "source": [
    "Run the analysis for 10 scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06e43e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:27:25.813148Z",
     "start_time": "2025-04-16T11:27:25.739893Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nAnalyzing conflicts in scenarios...\")\n",
    "conflict_analyses = analyze_all_scenarios(intersection_cases[:10], root_av)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66428e27a5b57e",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "This section implements a logistic regression model for predicting collision risk in intersection scenarios.\n",
    "The implementation consists of two main functions:\n",
    "1. prepare_logistic_regression_data: Extracts and processes features from scenario data\n",
    "2. train_logistic_regression: Trains the model using the processed data\n",
    "The model uses 7 key features:\n",
    "- Minimum distance between vehicles\n",
    "- Average relative velocity\n",
    "- Minimum time to intersection\n",
    "- Average yaw angle difference\n",
    "- Average speed difference\n",
    "- Time to closest approach\n",
    "- Average relative acceleration\n",
    "The model is trained to classify scenarios into three risk levels:\n",
    "- LOW (0): Safe situations\n",
    "- MEDIUM (1): Situations requiring attention\n",
    "- HIGH (2): Critical situations\n",
    "using predefined thresholds for distance, TTC, PET, velocity, and intersection angle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb88a9e6d4b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_logistic_regression_data(scenario_data):\n",
    "    \"\"\"\n",
    "    Prepares scenario data for logistic regression by extracting relevant features.\n",
    "    \n",
    "    This function processes trajectory data to create a feature vector for collision prediction.\n",
    "    It uses multiple metrics to determine if a scenario represents a collision:\n",
    "    - Minimum distance between vehicles\n",
    "    - Time to Collision (TTC)\n",
    "    - Post-Encroachment Time (PET)\n",
    "    - Relative velocity\n",
    "    \n",
    "    Thresholds for collision classification:\n",
    "    - Distance: < 0.5m (critical distance)\n",
    "    - TTC: < 0.3s AND distance < 2.0m (critical time to collision)\n",
    "    - PET: < 0.1s AND distance < 2.0m (critical post-encroachment time)\n",
    "    - Velocity: > 10.0 m/s AND distance < 1.0m (high speed and critical distance)\n",
    "    \n",
    "    Args:\n",
    "        scenario_data (dict): Dictionary containing scenario features including:\n",
    "            - motion_data: Vehicle motion states\n",
    "            - slices: Indices marking different vehicles' data\n",
    "            - timestep: Timestamps for motion data\n",
    "            \n",
    "    Returns:\n",
    "        tuple: (features, collision_label) where:\n",
    "            - features: numpy array of extracted features\n",
    "            - collision_label: 1 for collision, 0 for no collision\n",
    "    \"\"\"\n",
    "    def extract_features(motion_data, slices, timestep):\n",
    "        \"\"\"\n",
    "        Extracts relevant features for collision prediction.\n",
    "        \n",
    "        Features extracted:\n",
    "        1. Minimum distance between vehicles\n",
    "        2. Average relative velocity\n",
    "        3. Minimum time to intersection\n",
    "        4. Average yaw angle difference\n",
    "        5. Average speed difference\n",
    "        6. Time to closest approach\n",
    "        7. Average relative acceleration\n",
    "        \n",
    "        Args:\n",
    "            motion_data: Raw motion data for all vehicles\n",
    "            slices: Indices marking different vehicles' data\n",
    "            timestep: Timestamps for motion data\n",
    "            \n",
    "        Returns:\n",
    "            numpy.array: Feature vector containing the 7 features listed above\n",
    "        \"\"\"\n",
    "        # Get ego vehicle (AV) and other vehicle trajectories\n",
    "        ego_motion = motion_data[slices[0]:slices[1]]\n",
    "        other_motion = motion_data[slices[1]:slices[2]]\n",
    "        \n",
    "        # Interpolate trajectories to common length for consistent analysis\n",
    "        target_length = 100  # Fixed number of points for interpolation\n",
    "        t_ego = np.linspace(0, 1, len(ego_motion))\n",
    "        t_other = np.linspace(0, 1, len(other_motion))\n",
    "        t_common = np.linspace(0, 1, target_length)\n",
    "        \n",
    "        # Initialize interpolated arrays\n",
    "        ego_interp = np.zeros((target_length, ego_motion.shape[1]))\n",
    "        other_interp = np.zeros((target_length, other_motion.shape[1]))\n",
    "        \n",
    "        # Interpolate each component of the trajectories\n",
    "        for i in range(ego_motion.shape[1]):\n",
    "            ego_interp[:, i] = np.interp(t_common, t_ego, ego_motion[:, i])\n",
    "            other_interp[:, i] = np.interp(t_common, t_other, other_motion[:, i])\n",
    "        \n",
    "        # Calculate features using interpolated trajectories\n",
    "        relative_distance = np.linalg.norm(ego_interp[:, :2] - other_interp[:, :2], axis=1)\n",
    "        relative_velocity = np.linalg.norm(ego_interp[:, 2:4] - other_interp[:, 2:4], axis=1)\n",
    "        time_to_intersection = relative_distance / (relative_velocity + 1e-6)  # Avoid division by zero\n",
    "        \n",
    "        # Calculate yaw angle difference (normalized to [0, pi])\n",
    "        yaw_diff = np.abs(ego_interp[:, 6] - other_interp[:, 6])\n",
    "        yaw_diff = np.minimum(yaw_diff, 2*np.pi - yaw_diff)\n",
    "        \n",
    "        # Calculate speed difference\n",
    "        ego_speed = np.linalg.norm(ego_interp[:, 2:4], axis=1)\n",
    "        other_speed = np.linalg.norm(other_interp[:, 2:4], axis=1)\n",
    "        speed_diff = np.abs(ego_speed - other_speed)\n",
    "        \n",
    "        # Calculate time to closest approach\n",
    "        min_dist_idx = np.argmin(relative_distance)\n",
    "        time_to_closest = t_common[min_dist_idx]\n",
    "        \n",
    "        # Calculate relative acceleration\n",
    "        ego_acc = np.linalg.norm(ego_interp[:, 4:6], axis=1)\n",
    "        other_acc = np.linalg.norm(other_interp[:, 4:6], axis=1)\n",
    "        rel_acc = np.abs(ego_acc - other_acc)\n",
    "        \n",
    "        # Combine features into feature vector\n",
    "        features = np.array([\n",
    "            relative_distance.min(),          # Minimum distance\n",
    "            relative_velocity.mean(),         # Average relative velocity\n",
    "            time_to_intersection.min(),       # Minimum time to intersection\n",
    "            yaw_diff.mean(),                  # Average yaw angle difference\n",
    "            speed_diff.mean(),                # Average speed difference\n",
    "            time_to_closest,                  # Time to closest approach\n",
    "            rel_acc.mean()                    # Average relative acceleration\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "\n",
    "    # Extract features for all timesteps\n",
    "    features = extract_features(\n",
    "        scenario_data['motion_data'],\n",
    "        scenario_data['slices'],\n",
    "        scenario_data['timestep']\n",
    "    )\n",
    "    \n",
    "    # Interpolate trajectories for collision detection\n",
    "    ego_motion = scenario_data['motion_data'][scenario_data['slices'][0]:scenario_data['slices'][1]]\n",
    "    other_motion = scenario_data['motion_data'][scenario_data['slices'][1]:scenario_data['slices'][2]]\n",
    "    \n",
    "    target_length = 100\n",
    "    t_ego = np.linspace(0, 1, len(ego_motion))\n",
    "    t_other = np.linspace(0, 1, len(other_motion))\n",
    "    t_common = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    ego_interp = np.zeros((target_length, ego_motion.shape[1]))\n",
    "    other_interp = np.zeros((target_length, other_motion.shape[1]))\n",
    "    \n",
    "    for i in range(ego_motion.shape[1]):\n",
    "        ego_interp[:, i] = np.interp(t_common, t_ego, ego_motion[:, i])\n",
    "        other_interp[:, i] = np.interp(t_common, t_other, other_motion[:, i])\n",
    "    \n",
    "    # Calculate collision metrics\n",
    "    min_distance = np.min(np.linalg.norm(ego_interp[:, :2] - other_interp[:, :2], axis=1))\n",
    "    ttc = calculate_time_to_collision(ego_motion, other_motion)\n",
    "    pet = calculate_post_encroachment_time(ego_motion, other_motion)\n",
    "    relative_velocity = np.linalg.norm(ego_interp[:, 2:4] - other_interp[:, 2:4], axis=1).mean()\n",
    "    \n",
    "    # Determine collision label based on multiple criteria\n",
    "    # A scenario is considered a collision if ANY of these conditions are met:\n",
    "    collision_label = 1 if (\n",
    "        min_distance < 0.5 or  # Critical distance threshold\n",
    "        (ttc < 0.3 and min_distance < 2.0) or  # Critical TTC with small distance\n",
    "        (pet < 0.1 and min_distance < 2.0) or  # Critical PET with small distance\n",
    "        (relative_velocity > 10.0 and min_distance < 1.0)  # High speed with critical distance\n",
    "    ) else 0\n",
    "    \n",
    "    return features, collision_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb0006",
   "metadata": {},
   "source": [
    "Logistic Regression Training Function\n",
    "This function implements the training process for the logistic regression model:\n",
    "1. Prepares and preprocesses the training data\n",
    "2. Handles class imbalance using class weights\n",
    "3. Performs cross-validation to ensure model robustness\n",
    "4. Evaluates model performance using multiple metrics\n",
    "Key features:\n",
    "- Uses StandardScaler for feature normalization\n",
    "- Implements stratified sampling for balanced train/test splits\n",
    "- Includes comprehensive model evaluation metrics\n",
    "The function returns both the trained model and the fitted scaler for future predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(intersection_cases, root_path):\n",
    "    \"\"\"\n",
    "    Trains a logistic regression model on intersection scenarios.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    import numpy as np\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for _, case in intersection_cases.iterrows():\n",
    "        scenario_id = case['log_id']\n",
    "        features = analyze_intersection_scenario(scenario_id, root_path)\n",
    "        \n",
    "        if features:\n",
    "            scenario_features, collision_label = prepare_logistic_regression_data(features)\n",
    "            X.append(scenario_features)\n",
    "            y.append(collision_label)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"\\nClass distribution in dataset:\")\n",
    "    print(f\"Collisions (1): {np.sum(y == 1)}\")\n",
    "    print(f\"No collisions (0): {np.sum(y == 0)}\")\n",
    "    \n",
    "    # Si hay muy pocas muestras de alguna clase, ajustar los umbrales\n",
    "    if np.sum(y == 1) < 100 or np.sum(y == 0) < 100:\n",
    "        print(\"\\nWarning: Very imbalanced dataset. Consider adjusting collision thresholds.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train logistic regression model with class weights\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    print(\"\\nCross-validation scores:\", cv_scores)\n",
    "    print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(\"\\nTest set results:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd20ee",
   "metadata": {},
   "source": [
    "Predict Collision Function\n",
    "This function predicts the risk level for a given scenario using either a trained model or a rule-based system.\n",
    "The risk levels are:\n",
    "- LOW (0): Safe situation\n",
    "- MEDIUM (1): Requires attention\n",
    "- HIGH (2): Critical situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b011cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_collision(model, scaler, scenario_data):\n",
    "    \"\"\"\n",
    "    Predicts risk level for a given scenario.\n",
    "    \n",
    "    This function uses either a trained model or a rule-based system to classify\n",
    "    the risk level of a scenario. The risk levels are:\n",
    "    - LOW (0): Safe situation\n",
    "    - MEDIUM (1): Requires attention\n",
    "    - HIGH (2): Critical situation\n",
    "    \n",
    "    Risk scoring system:\n",
    "    - Distance factors:\n",
    "        * < 0.5m: 4 points (critical)\n",
    "        * < 2.0m: 2 points (attention)\n",
    "        * < 5.0m: 1 point (moderate)\n",
    "    \n",
    "    - Time factors (TTC):\n",
    "        * < 0.3s: 4 points (critical)\n",
    "        * < 1.0s: 2 points (attention)\n",
    "        * < 2.0s: 1 point (moderate)\n",
    "    \n",
    "    - PET factors:\n",
    "        * < 0.1s: 4 points (critical)\n",
    "        * < 0.3s: 2 points (attention)\n",
    "        * < 0.5s: 1 point (moderate)\n",
    "    \n",
    "    - Velocity factors:\n",
    "        * > 15.0 m/s and distance < 2.0m: 4 points\n",
    "        * > 10.0 m/s and distance < 5.0m: 2 points\n",
    "        * > 5.0 m/s and distance < 7.0m: 1 point\n",
    "    \n",
    "    - Intersection angle factors:\n",
    "        * > 150°: 2 points (near frontal)\n",
    "        * > 120°: 1 point (acute angle)\n",
    "    \n",
    "    Final risk classification:\n",
    "    - HIGH risk: score >= 10\n",
    "    - MEDIUM risk: score >= 5\n",
    "    - LOW risk: score < 5\n",
    "    \n",
    "    Args:\n",
    "        model: Trained logistic regression model\n",
    "        scaler: Fitted StandardScaler\n",
    "        scenario_data: Dictionary containing scenario features\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction, probability) where:\n",
    "            - prediction: 0 for LOW, 1 for MEDIUM, 2 for HIGH risk\n",
    "            - probability: Probability of highest risk level\n",
    "    \"\"\"\n",
    "    if model is None or scaler is None:\n",
    "        print(\"\\nUsing simple threshold-based classification...\")\n",
    "        ego_motion = scenario_data['motion_data'][scenario_data['slices'][0]:scenario_data['slices'][1]]\n",
    "        other_motion = scenario_data['motion_data'][scenario_data['slices'][1]:scenario_data['slices'][2]]\n",
    "        \n",
    "        # Interpolate trajectories\n",
    "        target_length = 100\n",
    "        t_ego = np.linspace(0, 1, len(ego_motion))\n",
    "        t_other = np.linspace(0, 1, len(other_motion))\n",
    "        t_common = np.linspace(0, 1, target_length)\n",
    "        \n",
    "        ego_interp = np.zeros((target_length, ego_motion.shape[1]))\n",
    "        other_interp = np.zeros((target_length, other_motion.shape[1]))\n",
    "        \n",
    "        for i in range(ego_motion.shape[1]):\n",
    "            ego_interp[:, i] = np.interp(t_common, t_ego, ego_motion[:, i])\n",
    "            other_interp[:, i] = np.interp(t_common, t_other, other_motion[:, i])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        min_distance = np.min(np.linalg.norm(ego_interp[:, :2] - other_interp[:, :2], axis=1))\n",
    "        ttc = calculate_time_to_collision(ego_interp, other_interp)\n",
    "        pet = calculate_post_encroachment_time(ego_interp, other_interp)\n",
    "        relative_velocity = np.linalg.norm(ego_interp[:, 2:4] - other_interp[:, 2:4], axis=1).mean()\n",
    "        \n",
    "        # Calculate intersection angle\n",
    "        ego_direction = ego_interp[-1, :2] - ego_interp[0, :2]\n",
    "        other_direction = other_interp[-1, :2] - other_interp[0, :2]\n",
    "        intersection_angle = np.arccos(np.dot(ego_direction, other_direction) / \n",
    "                                    (np.linalg.norm(ego_direction) * np.linalg.norm(other_direction)))\n",
    "        intersection_angle = np.degrees(intersection_angle)\n",
    "        \n",
    "        print(f\"\\nScenario metrics:\")\n",
    "        print(f\"Minimum distance: {min_distance:.2f}m\")\n",
    "        print(f\"TTC: {ttc:.2f}s\")\n",
    "        print(f\"PET: {pet:.2f}s\")\n",
    "        print(f\"Relative velocity: {relative_velocity:.2f}m/s\")\n",
    "        print(f\"Intersection angle: {intersection_angle:.2f}°\")\n",
    "        \n",
    "        # Risk scoring system\n",
    "        risk_score = 0\n",
    "        \n",
    "        # Distance factors\n",
    "        if min_distance < 0.5:  # Critical distance\n",
    "            risk_score += 4\n",
    "        elif min_distance < 2.0:  # Attention distance\n",
    "            risk_score += 2\n",
    "        elif min_distance < 5.0:  # Moderate distance\n",
    "            risk_score += 1\n",
    "        \n",
    "        # Time factors (TTC)\n",
    "        if ttc < 0.3:  # Critical TTC\n",
    "            risk_score += 4\n",
    "        elif ttc < 1.0:  # Attention TTC\n",
    "            risk_score += 2\n",
    "        elif ttc < 2.0:  # Moderate TTC\n",
    "            risk_score += 1\n",
    "        \n",
    "        # PET factors\n",
    "        if pet < 0.1:  # Critical PET\n",
    "            risk_score += 4\n",
    "        elif pet < 0.3:  # Attention PET\n",
    "            risk_score += 2\n",
    "        elif pet < 0.5:  # Moderate PET\n",
    "            risk_score += 1\n",
    "        \n",
    "        # Velocity factors\n",
    "        if relative_velocity > 15.0 and min_distance < 2.0:  # High speed and critical distance\n",
    "            risk_score += 4\n",
    "        elif relative_velocity > 10.0 and min_distance < 5.0:  # Moderate speed and attention distance\n",
    "            risk_score += 2\n",
    "        elif relative_velocity > 5.0 and min_distance < 7.0:  # Low speed and moderate distance\n",
    "            risk_score += 1\n",
    "        \n",
    "        # Intersection angle factors\n",
    "        if intersection_angle > 150:  # Near frontal\n",
    "            risk_score += 2\n",
    "        elif intersection_angle > 120:  # Acute angle\n",
    "            risk_score += 1\n",
    "        \n",
    "        # Final risk classification\n",
    "        if risk_score >= 10:  # HIGH risk\n",
    "            prediction = 2\n",
    "        elif risk_score >= 5:  # MEDIUM risk\n",
    "            prediction = 1\n",
    "        else:  # LOW risk\n",
    "            prediction = 0\n",
    "            \n",
    "        probability = 1.0\n",
    "        \n",
    "        return prediction, probability\n",
    "    \n",
    "    try:\n",
    "        features, _ = prepare_logistic_regression_data(scenario_data)\n",
    "        features_scaled = scaler.transform(features.reshape(1, -1))\n",
    "        \n",
    "        prediction = model.predict(features_scaled)[0]\n",
    "        probabilities = model.predict_proba(features_scaled)[0]\n",
    "        max_probability = np.max(probabilities)\n",
    "        \n",
    "        return prediction, max_probability\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError using model: {str(e)}\")\n",
    "        print(\"Using simple classification as fallback...\")\n",
    "        return predict_collision(None, None, scenario_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb372b",
   "metadata": {},
   "source": [
    "Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bfa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining logistic regression model...\")\n",
    "available_scenarios = []\n",
    "for _, case in intersection_cases.iterrows():\n",
    "    scenario_id = case['log_id']\n",
    "    filename = get_scenario_filename(scenario_id, root_av)\n",
    "    if filename is not None:\n",
    "        available_scenarios.append(case)\n",
    "\n",
    "print(f\"\\nTotal available scenarios: {len(available_scenarios)}\")\n",
    "\n",
    "# We use all the data except the last 10 for training\n",
    "train_data = pd.DataFrame(available_scenarios[:-10])\n",
    "test_data = pd.DataFrame(available_scenarios[-10:])\n",
    "\n",
    "print(f\"Using {len(train_data)} scenarios for training\")\n",
    "print(f\"Using {len(test_data)} scenarios for testing\")\n",
    "\n",
    "model, scaler = train_logistic_regression(train_data, root_av)\n",
    "\n",
    "# Test predictions in the last 10 scenarios\n",
    "print(\"\\nPredicting last 10 scenarios:\")\n",
    "for _, case in test_data.iterrows():\n",
    "    scenario_id = case['log_id']\n",
    "    test_scenario = analyze_intersection_scenario(scenario_id, root_av)\n",
    "    if test_scenario:\n",
    "        try:\n",
    "            prediction, probability = predict_collision(model, scaler, test_scenario)\n",
    "            if prediction is not None:\n",
    "                risk_level = ['LOW', 'MEDIUM', 'HIGH'][prediction]\n",
    "                print(f\"\\nScenario {scenario_id}:\")\n",
    "                print(f\"Risk Level: {risk_level}\")\n",
    "                print(f\"Confidence: {probability:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError predicting scenario {scenario_id}: {str(e)}\")\n",
    "            print(\"Using simple classification as fallback...\")\n",
    "            prediction, probability = predict_collision(None, None, test_scenario)\n",
    "            if prediction is not None:\n",
    "                risk_level = ['LOW', 'MEDIUM', 'HIGH'][prediction]\n",
    "                print(f\"\\nScenario {scenario_id}:\")\n",
    "                print(f\"Risk Level: {risk_level}\")\n",
    "                print(f\"Confidence: {probability:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conflict-resolution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
