{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_multiclass_features_and_labels(conflict_analyses):\n",
    "    X_multi = []\n",
    "    y_multi = []\n",
    "    risk_map = {'LOW': 0, 'MEDIUM': 1, 'HIGH': 2}\n",
    "    for entry in conflict_analyses:\n",
    "        features, _ = prepare_logistic_regression_data(entry)\n",
    "        risk_level = entry['metrics']['risk_level']  # This is \"LOW\", \"MEDIUM\", or \"HIGH\"\n",
    "        X_multi.append(features)\n",
    "        y_multi.append(risk_map[risk_level])\n",
    "    return np.array(X_multi), np.array(y_multi)"
   ],
   "id": "ecb3596511fc5fea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_logistic_regression_multiclass(intersection_cases, root_path):\n",
    "    \"\"\"\n",
    "    Trains a multi-class logistic regression model (LOW, MEDIUM, HIGH) with SMOTE for class balancing.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    risk_map = {'LOW': 0, 'MEDIUM': 1, 'HIGH': 2}\n",
    "\n",
    "    for _, case in intersection_cases.iterrows():\n",
    "        scenario_id = case['log_id']\n",
    "        features = analyze_intersection_scenario(scenario_id, root_path)\n",
    "        if features:\n",
    "            # Get risk level from scenario analysis\n",
    "            conflict_analysis = analyze_scenario_conflicts(features)\n",
    "            risk_level = conflict_analysis['metrics']['risk_level']  # \"LOW\", \"MEDIUM\", \"HIGH\"\n",
    "            scenario_features, _ = prepare_logistic_regression_data(features)\n",
    "            y.append(risk_map[risk_level])\n",
    "            X.append(scenario_features)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(\"\\nClass distribution in dataset:\")\n",
    "    print(f\"LOW (0): {np.sum(y == 0)}\")\n",
    "    print(f\"MEDIUM (1): {np.sum(y == 1)}\")\n",
    "    print(f\"HIGH (2): {np.sum(y == 2)}\")\n",
    "\n",
    "    if np.sum(y == 0) < 10 or np.sum(y == 1) < 10 or np.sum(y == 2) < 10:\n",
    "        print(\"\\nWarning: Very imbalanced dataset. Proceeding anyway.\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Number of training data samples: {len(y_train)}\")\n",
    "    print(f\"Number of test data samples: {len(y_test)}\")\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "    print(f\"After SMOTE:\")\n",
    "    print(f\"LOW (0): {np.sum(y_train_res == 0)}\")\n",
    "    print(f\"MEDIUM (1): {np.sum(y_train_res == 1)}\")\n",
    "    print(f\"HIGH (2): {np.sum(y_train_res == 2)}\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced', multi_class='multinomial')\n",
    "    model.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train_res, cv=5)\n",
    "    print(\"\\nCross-validation scores:\", cv_scores)\n",
    "    print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(\"\\nTest set results:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['LOW', 'MEDIUM', 'HIGH']))\n",
    "\n",
    "    labels = ['LOW', 'MEDIUM', 'HIGH']\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "    conf_df = pd.DataFrame(conf_matrix, index=labels, columns=labels)\n",
    "    print(\"\\nConfusion Matrix with Labels:\")\n",
    "    print(conf_df)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return model, scaler"
   ],
   "id": "8fb38b938a1c78ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nSplitting data into training and testing sets...\")\n",
    "available_scenarios = []\n",
    "for _, case in intersection_cases.iterrows():\n",
    "    scenario_id = case['log_id']\n",
    "    filename = get_scenario_filename(scenario_id, root_av)\n",
    "    if filename is not None:\n",
    "        available_scenarios.append(case)\n",
    "\n",
    "print(f\"\\nTotal available scenarios: {len(available_scenarios)}\")\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "split_idx = int(0.8 * len(available_scenarios))\n",
    "train_data = pd.DataFrame(available_scenarios[:split_idx])  # 80% for training\n",
    "test_data = pd.DataFrame(available_scenarios[split_idx:])   # 20% for testing\n",
    "\n",
    "print(f\"Using {len(train_data)} scenarios for training\")\n",
    "print(f\"Using {len(test_data)} scenarios for testing\")\n",
    "\n",
    "# Train the logistic regression model\n",
    "print(\"\\nTraining logistic regression model...\")\n",
    "model, scaler = train_logistic_regression_multiclass(train_data, root_av)\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "# Test predictions on 20% of the data\n",
    "print(\"\\nPredicting test scenarios:\")\n",
    "\n",
    "scenario_ids = []\n",
    "risk_levels = []\n",
    "confidences = []\n",
    "\n",
    "for _, case in test_data.iterrows():\n",
    "    scenario_id = case['log_id']\n",
    "    test_scenario = analyze_intersection_scenario(scenario_id, root_av)\n",
    "\n",
    "    if test_scenario:\n",
    "        try:\n",
    "            initial_features, _ = prepare_logistic_regression_data(test_scenario)\n",
    "            initial_features_scaled = scaler.transform(initial_features.reshape(1, -1))\n",
    "            prediction = model.predict(initial_features_scaled)[0]\n",
    "            probabilities = model.predict_proba(initial_features_scaled)[0]\n",
    "            max_probability = np.max(probabilities)\n",
    "            risk_level = ['LOW', 'MEDIUM', 'HIGH'][prediction]\n",
    "\n",
    "            scenario_ids.append(scenario_id)\n",
    "            risk_levels.append(risk_level)\n",
    "            confidences.append(max_probability)\n",
    "        except Exception as e:\n",
    "            prediction, probability = predict_collision(None, None, test_scenario)\n",
    "            if prediction is not None:\n",
    "                risk_level = ['LOW', 'MEDIUM', 'HIGH'][prediction]\n",
    "                scenario_ids.append(scenario_id)\n",
    "                risk_levels.append(risk_level)\n",
    "                confidences.append(probability)\n",
    "    # If test_scenario is None, skip\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Scenario ID': scenario_ids,\n",
    "    'Risk Level': risk_levels,\n",
    "    'Confidence': confidences\n",
    "})\n",
    "\n",
    "print(\"Counts of each risk level in test predictions:\")\n",
    "print(results_df['Risk Level'].value_counts())\n",
    "\n",
    "counts = results_df['Risk Level'].value_counts()\n",
    "for level in ['LOW', 'MEDIUM', 'HIGH']:\n",
    "    print(f\"{level}: {counts.get(level, 0)}\")\n",
    "\n",
    "results_df.to_csv('all_test_predictions.csv', index=False)\n",
    "print(\"\\nPrediction Results Table:\")\n",
    "display(FileLink('all_test_predictions.csv'))\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
